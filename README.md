알고리즘 문제 모음집.

# 행동 패턴
1. 문제를 정독하고, 무엇을 묻는 문제인지 판별한다.
2. 문제해결을 위한 적절한 자료구조를 선택한다.
3. divide & conquer. 작은 단위부터 쪼개어 접근한다.
4. 큰 청사진을 먼저 선언하고, 세부 사항을 설계한다.
5. 변수, 초기값 등에 유의하며 문제를 푼다.

##### 입/출력
n = int(input())
data = list(map(int, input().split()))
data = sorted(list(map(int, input().split())), reverse=False)

print(n)
print(data)

import sys
speed = sys.stdin.readline().rstrip()

print(speed)

##### 유용 라이브러리
itertools, heapq, bisect, collections, math

##### sorting
r = sorted([3,1,4,5,6])
r_r = sorted([3,1,4,5,6], reverse=True)
print(r)
print(r_r)

a = [('a', 1), ('c', 3), ('b', 2)]
b = sorted(a, key=lambda x:x[1], reverse=True)
print(b)

##### for
for i in range(1, len(data)): // enumerate

##### implementation
일반적으로 알고리즘 문제에서의 2차원 공간은 행렬을 의미하며
시뮬레이션 / 탐색 문제에서는 '방향 벡터'가 자주 사용
"""
    dx = [0, -1, 0, 1]
    dy = [1, 0, -1, 0]
    x, y = 2, 2

    for i in range(4):
        nx = x + dx[i]
        ny = y + dy[i]
        print(nx, ny)

    * 2칸+1칸씩 움직이더라도 벡터이니...
    steps = [(-2, -1), (-1, -2), (1, -2), (2, -1), (2, 1), (1, 2), (-1, 2), (-2, 1)]
"""

##### 탐색
많은 양의 데이터 중 내가 원하는 데이터를 찾고자 할 때
# 스택: 프링글스, 삽입/삭제, 입구/출구 동일
"""
list + append + pop으로 충분하다 O(1)

stack = list()

stack.append(1)
stack.append(3)
stack.append(5)
stack.pop()

print(stack)  # 최하단부터
print(stack[::-1])  # 최상단부터
"""

# 큐: 은행창구, 대기열
"""
from collections import deque

queue = deque()

queue.append(1)
queue.append(3)
queue.append(5)
queue.popleft()

print(queue)  # 먼저 들어온 순서대로
queue.reverse()  # 역순으로 바꾸기
print(queue)  # 나중에 들어온 원소부터 출력
"""

# 우선순위 큐
가장 우선순위가 높은 데이터
(가장 우선순위가 높은 데이터를 먼저 삭제한다)
1. 리스트
2. 힙
완전 이진트리의 일종. 부모가 언제나 자식보다 크거나 작거나
힙에서는 항상 루트 노드를 제거하고,
* 최소 힙: 루트 노드가 가장 작은 힙. 작은 데이터 우선 삭제
* 최대 힙: 루트 노드가 가장 큰 힙. 큰 데이터 우선 삭제

heapify를 통해 기존 리스트를 heap으로 변경 가능하고,
주로 heappush, heappop 메쏘드 사용.


# 재귀함수: 자기 자신을 다시 호출, dfs구현시 자주 사용
사용 시, 반드시 종료 조건을 명시할 것
ex) 팩토리얼, 최대공약수(유클리드 호제법)

# DFS: depth first search
스택 혹은 재귀함수를 주로 사용하며,
1. 탐색 노드를 스택에 삽입하고 방문 처리
2. 스택의 최상단 노드에 방문하지 않은 인접 노드가 있다면, 스택에 삽입하고 방문 처리.
    방문하지 않은 인접 노드가 없다면, 스택에서 최상단 노드를 꺼낸다
3. 2번 과정을 수행할 수 없을 때까지 반복

# BFS: breadth first search
큐를 이용하며, 가까운 노드부터 우선하여 탐색
1. 탐색 노드를 큐에 삽입하고 방문 처리
2. 큐에서 노드를 꺼낸 뒤, 해당 인접 노드 중에서 방문하지 않은 노드를 모두 큐에 삽입하고 방문 처리
3. 2번 과정을 수행할 수 없을 때까지 반복

# 정렬
일반적으로 문제 상황에 따른 적절한 알고리즘이 공식처럼 사용됨

1. 선택 정렬 - O(n^2)
처리되지 않은 데이터 중에서, 가장 작은 데이터를 선택하여 맨 앞에 있는 데이터와 바꾸는 것을 반복

2. 삽입 정렬 - O(n^2)
처리되지 않은 데이터를 하나씩 골라, 적절한 위치에 삽입
(선택 정렬에 비해 구현 난이도는 높지만, 성능은 더 우수)

3. 퀵 정렬 - O(nlogn)
기준 데이터를 설정하고 그 기준보다 큰 데이터와 작은 데이터의 위치를 바꾸는 방법
첫번째 데이터를 기준으로 주로 삼으며, 정렬 라이브러리의 근간
왼쪽에서는 피벗값보다 큰 값을, 오른쪽에서는 작은 값을 찾는다. 그리고 위치가 엇갈리는 경우, 피벗값과 작은 값의 위치를 변경.

4. 계수 정렬 - O(n+k)
특정한 조건에 부합하는 경우에만 사용 가능하지만, 매우 빠름.
데이터 크기의 범위가 제한되어 정수 형태로 표현할 수 있을 때 사용 가능.
동일한 값을 가지는 데이터가 여러 개 등장할 때 유리.

# 이진 탐색
순차: 리스트 안의 특정한 데이터를 찾기 위해 앞에서부터 데이터를 하나씩 확인하는 방법
이진: 정렬되어 있는 리스트에서 탐색 범위를 절반씩 좁혀가며 데이터를 탐색하는 방법 (시작, 중간, 끝 활용)

# 다이나믹 프로그래밍
메모리를 적절히 사용하여 수행 시간 효율성을 비약적으로 향상 시키는 방법
top-down, bottom-up 방식으로 구성되며 이미 계산된 결과는 별도 메모리에 저장하여 다시 계산하지 않도록 한다.

1. 최적 부분 구조(Optimal Substructure)
큰 문제를 작은 문제로 나눌 수 있으며, 작은 문제의 답을 모아서 큰 문제를 해결합니다.

2. 중복되는 부분 문제(Overlapping Subproblem)
동일한 작은 문제를 반복적으로 해결합니다.

두 조건을 모두 만족할 시, 본 방식 활용.

* 메모이제이션(Memoization)=caching
한 번 계산한 결과를 메모리에 메모하는 기법


##### 최단 경로 알고리즘
- 특정 노드에서 출발하여 다른 모든 노드로 가는 최단 경로 계산(BFS, DFS)
- 그리디 알고리즘으로 분류(=매 상황, 비용이 가장 적게 드는 노드 선택)
- 특히 노드 간 수행 cost가 다를 때, 다익스트라 알고리즘으로 분류하고 아래와 같은 과정을 거친다.

1. 최단 거리 테이블 초기화하고 출발 노드 설정
2. 방문하지 않는 노드 중, 최단 거리가 가장 짧은 노드 선택
3. 해당 노드를 거쳐 다른 노드로 가는 비용을 계산하여 최단 거리 테이블 갱신
4. 2/3번 과정 반복


##### Disjoint Set
서로 중복되지 않는 부분 집합들로 나눠진 원소들에 대한 정보를 저장하고 조작하는 자료구조.
즉, 공통 원소가 없는 '상호 배타적'인 부분 집합에 해당

* Union-Find
Disjoint Set을 표현할 때 사용하는 알고리즘
(비트 벡터, 배열, 링크드리스트 등 사용 가능하나 트리 주로 사용)

* 연산
1. make-set(x)
: 초기화, x를 유일한 원소로 하는 새로운 집합 생성

2. union(x, y)
: 합하기, x가 속한 집합과 y가 속한 집합을 합친다

3. find(x)
: 찾기, x가 속한 집합의 root node를 반환.

##### Dynamic Programming
적절한 자료구조를 택하고 점화식 구성에 힘쓴다.
그리고 조건에 맞게 초기값을 지정해준다.
- 숫자의 조합을 보거나 경우의 조합을 볼 것. 즉 나열한다.
- 혹시나 런타임 에러가 난다면 재귀로 해결할 것